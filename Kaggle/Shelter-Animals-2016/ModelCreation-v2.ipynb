{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## To-Do:\n",
    "\n",
    "* Explore dataset\n",
    "    * Outlier Analysis\n",
    "* Feature engineering\n",
    "    * column with the identification if the animal has been given a name\n",
    "    * column with the period of day of the outcome (0-8;9-18;19-24)\n",
    "        * verify what is the working period in united states\n",
    "    * identify the weekends and holidays in united states\n",
    "    * season (winter, summer, ...)\n",
    "    * divide the sexuponoutcome in two columns\n",
    "        * sex (0, 1) for Male and Female;\n",
    "        * operation (0, 1) for representing Neutered (Spayed and Neutered) and Intact;\n",
    "    * transform the age to years\n",
    "    \n",
    "* Ideas/ToDo: \n",
    "    * check if is algorithm evaluations we shouldn't separate the approaches by cats and dogs\n",
    "        * dogs tend to be returned to owner more often then cats;\n",
    "        * cats are transferred more often then dogs\n",
    "    * get importance features and create a model with only the most important \n",
    "    * Evaluation with log loss and not accuracy\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadTrainAndTestDatasets():\n",
    "    train_df = pd.read_csv(\"data/train.csv\")\n",
    "    test_df = pd.read_csv(\"data/test.csv\")\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.crosstab(train_df[\"OutcomeType\"], train_df[\"OutcomeSubtype\"], margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Nota: a maior parte do código usa lambdas... eu preferia usar funcoes para brincar com \n",
    "#os parâmetros\n",
    "#Não estou ainda a usar estas funcoes\n",
    "#verificar o que é melhor (se passar a idade para dias ou se ter uma categoria) \n",
    "\n",
    "def has_name(name):\n",
    "    if name is np.nan:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def calc_age_in_years(x):\n",
    "    x = str(x)\n",
    "    if x == 'nan': return 0\n",
    "    age = int(x.split()[0])\n",
    "    if x.find('year') > -1: return age \n",
    "    if x.find('month')> -1: return age / 12.\n",
    "    if x.find('week')> -1: return age / 52.\n",
    "    if x.find('day')> -1: return age / 365.\n",
    "    else: return 0\n",
    "    \n",
    "def calc_age_category(x):\n",
    "    if x < 3: return 0\n",
    "    if x < 5: return 1\n",
    "    if x < 10: return 2\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def part_of_day(x):\n",
    "    hour = datetime.strptime(x, '%Y-%m-%d %H:%M:%S').hour\n",
    "    if hour < 9: return '0-8'\n",
    "    if hour < 19: return '9-18'\n",
    "    return '19-24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start='2013-01-01 00:00:00', end='2016-02-28 00:00:00')\n",
    "\n",
    "def is_holiday(x):\n",
    "    dt = datetime.strptime(x, '%Y-%m-%d %H:%M:%S')    \n",
    "    if dt in holidays:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_season(x):\n",
    "    dt = datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    \"\"\"\n",
    "    convert date to month and day as integer (md), e.g. 4/21 = 421, 11/17 = 1117, etc.\n",
    "    \"\"\"\n",
    "    m = dt.month * 100\n",
    "    d = dt.day\n",
    "    md = m + d\n",
    "\n",
    "    if ((md >= 301) and (md <= 531)):\n",
    "        return 'spring'\n",
    "    elif ((md > 531) and (md < 901)):\n",
    "        return 'summer'\n",
    "    elif ((md >= 901) and (md <= 1130)):\n",
    "        return 'fall'\n",
    "    \n",
    "    return 'winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_weekend(x):\n",
    "    # Return the day of the week as an integer, where Monday is 0 and Sunday is 6.\n",
    "    dt = datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    if dt.weekday() in [5, 6]:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeColumn(data):\n",
    "    from sklearn import preprocessing\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(data)\n",
    "    df_normalized = pd.DataFrame(x_scaled)\n",
    "    return df_normalized.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agetodays(x):\n",
    "    try:\n",
    "        y = x.split()\n",
    "    except:\n",
    "        return None \n",
    "    if 'year' in y[1]:\n",
    "        return float(y[0]) * 365\n",
    "    elif 'month' in y[1]:\n",
    "        return float(y[0]) * (365/12)\n",
    "    elif 'week' in y[1]:\n",
    "        return float(y[0]) * 7\n",
    "    elif 'day' in y[1]:\n",
    "        return float(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df = pd.read_csv(\"data/train.csv\")\n",
    "#test_df = pd.read_csv(\"data/test.csv\")\n",
    "#print(train_df['DateTime'][:10], train_df['DateTime'][:10].apply(part_of_day))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepareDatasets(train_df, test_df):\n",
    "    \n",
    "    print('-- Transformation step has begun --- ')\n",
    "    ## JOIN train and test datasets\n",
    "    all_data = pd.concat([train_df, test_df])\n",
    "    \n",
    "    train_length = train_df.shape[0]\n",
    "    \n",
    "    # NAME\n",
    "    ## New feature has_name\n",
    "    ## Drop Name column\n",
    "    all_data['has_name'] = all_data.Name.apply(has_name)\n",
    "    all_data.drop(['Name'], axis=1, inplace=True)\n",
    "    \n",
    "    print('  * NAME is completed! ')\n",
    "    \n",
    "    # DATETIME\n",
    "    ## Split date to year, month, day\n",
    "    ## Normalize values between 0 and 1\n",
    "    ## New features: is_weekend, is_holiday\n",
    "    ## Drop Datetime column\n",
    "    all_data['Year'] = pd.DatetimeIndex(all_data['DateTime']).year\n",
    "    all_data['Month'] = pd.DatetimeIndex(all_data['DateTime']).month\n",
    "    all_data['Day'] = pd.DatetimeIndex(all_data['DateTime']).day\n",
    "    all_data['part_of_day'] = all_data.DateTime.apply(part_of_day)\n",
    "    print('       # PART OF DAY is completed! ')\n",
    "    all_data['is_holiday'] = all_data.DateTime.apply(is_holiday)\n",
    "    print('       # IS HOLIDAY is completed! ')\n",
    "    all_data['is_weekend'] = all_data.DateTime.apply(is_weekend)\n",
    "    print('       # IS WEEKEND is completed! ')\n",
    "    all_data['season'] = all_data.DateTime.apply(get_season)\n",
    "    print('       # SEASON is completed! ')\n",
    "    all_data.drop([\"DateTime\"], axis=1, inplace=True)\n",
    "    \n",
    "    print('  * DATETIME is completed! ')\n",
    "    \n",
    "    #TODO: test if this has better results\n",
    "    #(Maria)Transform and normalize the age into years\n",
    "    #train_df[\"AgeInYears\"] = train_df.AgeuponOutcome.apply(calc_age_in_years)\n",
    "    #test_df[\"AgeInYears\"] = test_df.AgeuponOutcome.apply(calc_age_in_years)\n",
    "    \n",
    "    \n",
    "    # AGEUPONOUTCOME \n",
    "    ## Convert date to days\n",
    "    ## Fill NaN values with the median\n",
    "    ## Normalize values between 0 and 1\n",
    "    ## Drop AgeuponOutcome column\n",
    "    all_data['AgeUponOutcomeInDays'] = all_data['AgeuponOutcome'].map(agetodays)\n",
    "    all_data.loc[(all_data['AgeUponOutcomeInDays'].isnull()),'AgeUponOutcomeInDays'] = all_data['AgeUponOutcomeInDays'].median()\n",
    "    all_data.drop([\"AgeuponOutcome\"], axis=1, inplace=True)\n",
    "    \n",
    "    print('  * AGEUPONOUTCOME is completed! ')\n",
    "    \n",
    "    #Normalize columns\n",
    "    cols_to_norm = ['Year','Month', 'Day', 'AgeUponOutcomeInDays']\n",
    "    all_data[cols_to_norm] = all_data[cols_to_norm].apply(lambda x: (x - x.mean()) / (x.max() - x.min()))\n",
    "    \n",
    "    print('  * NORMALIZATION is completed! ')\n",
    "    \n",
    "    # OUTCOMETYPE\n",
    "    ## Separating target variable\n",
    "    train_outcome = all_data[\"OutcomeType\"][:train_length]\n",
    "    all_data.drop([\"OutcomeType\"], axis=1, inplace=True)\n",
    "    \n",
    "    print('  * OUTCOMETYPE is completed! ')\n",
    "        \n",
    "    # OUTCOMESUBTYPE\n",
    "    ## OutcomeSubtype are deleted\n",
    "    all_data.drop([\"OutcomeSubtype\"], axis=1, inplace=True)\n",
    "    \n",
    "    print('  * OUTCOMESUBTYPE is completed! ')\n",
    "    \n",
    "    # SEXUPONOUTCOME\n",
    "    ## Fill NaN with the mode\n",
    "    ## New feature_ is_spayed_or_neutered\n",
    "    ## Encode categorical to numeric\n",
    "    all_data['SexuponOutcome'].fillna(all_data['SexuponOutcome'].mode().iloc[0], inplace=True)\n",
    "    all_data[\"is_spayed_or_neutered\"] = all_data['SexuponOutcome'].apply(lambda e : 1 if 'spayed' in e or 'neutered' in e else 0 )\n",
    "\n",
    "    print('  * SEXUPONOUTCOME is completed! ')\n",
    "    \n",
    "    # ANIMALTYPE\n",
    "    ## Encode categorical to numeric\n",
    "    \n",
    "    \n",
    "    # BREED\n",
    "    ## extract new features: hair (short, medium, long) and is_mix \n",
    "    ## Encode categorical to numeric\n",
    "    all_data[\"is_mix\"] = all_data['Breed'].apply(lambda e : 1 if \"Mix\" in e else 0 )\n",
    "    \n",
    "    print('  * BREED is completed! ')\n",
    "    \n",
    "    # COLOR\n",
    "    ## new feature: has_multiple_colors\n",
    "    ## Encode categorical to numeric\n",
    "    all_data[\"has_multiple_colors\"] = all_data['Color'].apply(lambda e : 1 if len(str(e).split('/')) > 1 else 0 )\n",
    "    \n",
    "    print('  * COLOR is completed! ')\n",
    "    \n",
    "    #Deleting IDs\n",
    "    all_data.drop([\"AnimalID\"], axis=1, inplace=True)\n",
    "    all_data.drop([\"ID\"], axis=1, inplace=True)\n",
    "    \n",
    "    print('  * IDs is completed! ')\n",
    "    \n",
    "    \n",
    "    # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\n",
    "    #Encode the categorical data of all_data, column by column due memory restrictions\n",
    "    AnimalType_encoded = pd.get_dummies(all_data['AnimalType'], columns='AnimalType')\n",
    "    SexuponOutcome_encoded = pd.get_dummies(all_data['SexuponOutcome'], columns='SexuponOutcome')\n",
    "    Breed_encoded = pd.get_dummies(all_data['Breed'], columns='Breed')\n",
    "    Color_encoded = pd.get_dummies(all_data['Color'], columns='Color')\n",
    "    part_of_day_encoded = pd.get_dummies(all_data['part_of_day'], columns='part_of_day')\n",
    "    season_encoded = pd.get_dummies(all_data['season'], columns='season')\n",
    "    \n",
    "    print('  * GET DUMMIES is completed! ')\n",
    "    \n",
    "    # http://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "    all_data.drop([\"AnimalType\"], axis=1, inplace=True)\n",
    "    all_data.drop([\"SexuponOutcome\"], axis=1, inplace=True)\n",
    "    all_data.drop([\"Breed\"], axis=1, inplace=True)\n",
    "    all_data.drop([\"Color\"], axis=1, inplace=True)\n",
    "    all_data.drop([\"part_of_day\"], axis=1, inplace=True)\n",
    "    all_data.drop([\"season\"], axis=1, inplace=True)\n",
    "    \n",
    "    print('  * DROP GET DUMMIES is completed! ')\n",
    "    \n",
    "    all_data_encoded = pd.concat([all_data, part_of_day_encoded, season_encoded, AnimalType_encoded, \n",
    "                                  SexuponOutcome_encoded, Breed_encoded, Color_encoded], \n",
    "                                 axis=1)\n",
    "    \n",
    "    \n",
    "    #Split again for train and test\n",
    "    train = all_data_encoded[:train_length]\n",
    "    test = all_data_encoded[train_length:]\n",
    "    \n",
    "    print('-- Transformation step has finished --- ')\n",
    "    \n",
    "    return train_outcome, train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, log_loss\n",
    "\n",
    "def calculateCVMetrics(train, train_outcome, model):\n",
    "    \n",
    "    #Training a RF to get some metrics\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train, train_outcome, test_size=0.3)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    #y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    #print(classification_report(y_val, y_pred_val))\n",
    "    #print(accuracy_score(y_val, y_pred_val))\n",
    "    clf_probs = model.predict_proba(X_val)\n",
    "    print('Log Loss metric')\n",
    "    print(log_loss(y_val, clf_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate final model (with best parameters or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def CreateFinalModel(train, train_outcome, bestParams=False):\n",
    "    \n",
    "    \n",
    "    if bestParams:\n",
    "        rfc = RandomForestClassifier()\n",
    "        param_grid = { \n",
    "            'n_estimators': [500],\n",
    "            'max_features': ['auto', 'sqrt', 'log2']\n",
    "        }\n",
    "        model = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=10, n_jobs=4)\n",
    "    else:\n",
    "        model = RandomForestClassifier(n_estimators=250,n_jobs=5)\n",
    "    \n",
    "    model.fit(train, train_outcome)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create predictions and submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makePredictions(model, test):\n",
    "    return model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createCSVSubmissionFile(predictions, fileName):\n",
    "    \n",
    "    results = pd.read_csv(\"submissions/sample_submission.csv\")\n",
    "    \n",
    "    results['Adoption'], results['Died'], results['Euthanasia'], results['Return_to_owner'], \n",
    "    results['Transfer'] = predictions[:,0], predictions[:,1], predictions[:,2], predictions[:,3], \n",
    "    predictions[:,4]\n",
    "    results.to_csv(\"submissions/\" + fileName, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RUN ALL STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = loadTrainAndTestDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Transformation step has begun --- \n",
      "  * NAME is completed! \n",
      "       # PART OF DAY is completed! \n",
      "       # IS HOLIDAY is completed! \n",
      "       # IS WEEKEND is completed! \n",
      "       # SEASON is completed! \n",
      "  * DATETIME is completed! \n",
      "  * AGEUPONOUTCOME is completed! \n",
      "  * NORMALIZATION is completed! \n",
      "  * OUTCOMETYPE is completed! \n",
      "  * OUTCOMESUBTYPE is completed! \n",
      "  * SEXUPONOUTCOME is completed! \n",
      "  * BREED is completed! \n",
      "  * COLOR is completed! \n",
      "  * IDs is completed! \n",
      "  * GET DUMMIES is completed! \n",
      "  * DROP GET DUMMIES is completed! \n",
      "-- Transformation step has finished --- \n"
     ]
    }
   ],
   "source": [
    "train_outcome, train, test = prepareDatasets(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[['is_holiday', 'Year','Month', 'Day', 'AgeUponOutcomeInDays', '0-8', '9-18', '19-24', 'winter', 'summer',\n",
    "      'has_multiple_colors', 'is_mix', 'is_spayed_or_neutered']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_outcome.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "findBestParams = False\n",
    "finalModel = CreateFinalModel(train, train_outcome, findBestParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if findBestParams:\n",
    "    print(finalModel.best_params_)\n",
    "    calculateCVMetrics(train, train_outcome, finalModel.best_estimator_)\n",
    "else:\n",
    "    calculateCVMetrics(train, train_outcome, finalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = makePredictions(finalModel, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "fileName = \"submission_\" + now + \".csv\"\n",
    "createCSVSubmissionFile(predictions, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalModel.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(finalModel, prefit=True)\n",
    "X_new = model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newModel = CreateFinalModel(X_new, train_outcome, findBestParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if findBestParams:\n",
    "    print(newModel.best_params_)\n",
    "    calculateCVMetrics(X_new, train_outcome, newModel.best_estimator_)\n",
    "else:\n",
    "    calculateCVMetrics(X_new, train_outcome, newModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_new = model.transform(test)\n",
    "predictions = makePredictions(newModel, Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## XGBoost\n",
    "ToDo:\n",
    "- tuning parameters\n",
    "- split dataset of cats and dogs and make different models for each one\n",
    "- ensemble??\n",
    "- add more features\n",
    "- clean/organize notebook strucutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "#modelXGB = XGBClassifier(n_estimators=1000, learning_rate = 0.03, max_depth=6, subsample=0.7, \n",
    "#        colsample_bytree = 0.7, # gamma = 0.7, # max_delta_step=0.1, \n",
    "#        reg_lambda = 4, # min_child_weight=50, \n",
    "        #seed = seed, \n",
    "#                        ) \n",
    "modelXGB = XGBClassifier() \n",
    "    \n",
    "modelXGB.fit(train, train_outcome, eval_metric='mlogloss',)\n",
    "calculateCVMetrics(train, train_outcome, modelXGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictionsXGBoost = makePredictions(modelXGB, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "fileName = \"submission_\" + now + \".csv\"\n",
    "createCSVSubmissionFile(predictionsXGBoost, fileName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
